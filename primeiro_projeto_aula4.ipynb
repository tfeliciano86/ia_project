{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO84TBaJMaN1pSwGI+5641o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tfeliciano86/ia_project/blob/main/primeiro_projeto_aula4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XaQh5sE27V-x"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY='AIzaSyDhmYlUfPWNPSnx485xEwks46UY6Bj08q8'\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n"
      ],
      "metadata": {
        "id": "ayEHx_NM7Yjp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "listar modelos disponiveis"
      ],
      "metadata": {
        "id": "DV8c7Kj97tUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "oJnxG70E708k",
        "outputId": "ded3e64a-1973-4f64-fcff-585a2f4c9bf2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5\n",
        "      }"
      ],
      "metadata": {
        "id": "FMyYfsD49NuQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\"\n",
        "    }\n",
        ""
      ],
      "metadata": {
        "id": "KPpuz_EM_G_5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando modelo"
      ],
      "metadata": {
        "id": "I6WW5qScIAAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "omdxRYasIB_-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Preciso desenvolver um projeto inovador usando IA, pensei em algo sobre a doenca da dengue ou sobre a tragedia do rio grande do sul, como as pessoas podem ajudar ?.\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "2FttZHiGJay2",
        "outputId": "548ed0c4-a792-45d7-d54d-0829d4919bc1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Projeto Inovador de IA para a Doença da Dengue**\n",
            "\n",
            "**Objetivo:** Desenvolver um sistema de IA para melhorar a detecção, prevenção e tratamento da dengue.\n",
            "\n",
            "**Características:**\n",
            "\n",
            "* **Detecção Precoce:** Um aplicativo móvel equipado com IA que usa aprendizado de máquina para analisar sintomas e dados demográficos para identificar indivíduos com risco de desenvolver dengue.\n",
            "* **Monitoramento de Surtos:** Um sistema de monitoramento em tempo real que rastreia os casos de dengue usando dados de hospitais, clínicas e fontes de mídia social. A IA analisa esses dados para prever surtos e alertar as autoridades de saúde.\n",
            "* **Recomendações de Tratamento Personalizadas:** Um chatbot de IA que fornece recomendações de tratamento personalizadas com base nos sintomas e históricos médicos dos pacientes. Isso ajuda os profissionais de saúde a tomar decisões de tratamento mais informadas.\n",
            "* **Educação e Conscientização:** Uma plataforma online que fornece informações abrangentes sobre a dengue, incluindo sintomas, métodos de prevenção e opções de tratamento. A IA personaliza o conteúdo com base nas necessidades dos usuários, promovendo a conscientização e o autocuidado.\n",
            "\n",
            "**Benefícios:**\n",
            "\n",
            "* Detecção e diagnóstico precoces, resultando em melhores resultados de saúde.\n",
            "* Prevenção de surtos e mitigação de seu impacto na saúde pública.\n",
            "* Tratamento mais eficaz e personalizado, reduzindo a gravidade da doença.\n",
            "* Maior conscientização e empoderamento da comunidade para tomar medidas preventivas.\n",
            "\n",
            "**Projeto Inovador de IA para a Tragédia do Rio Grande do Sul**\n",
            "\n",
            "**Objetivo:** Desenvolver um sistema de IA para apoiar os esforços de ajuda e recuperação após desastres naturais.\n",
            "\n",
            "**Características:**\n",
            "\n",
            "* **Avaliação de Danos:** Um drone equipado com IA que coleta imagens aéreas e dados para avaliar a extensão dos danos e identificar áreas prioritárias para ajuda.\n",
            "* **Coordenação de Resposta:** Uma plataforma de gerenciamento de desastres baseada em IA que conecta organizações de ajuda, equipes de resposta a emergências e voluntários. A IA otimiza a alocação de recursos e coordena os esforços de resposta.\n",
            "* **Rastreamento de Sobreviventes:** Um aplicativo móvel que permite que sobreviventes se registrem e forneçam informações sobre suas necessidades. A IA analisa esses dados para identificar indivíduos vulneráveis e conectá-los com serviços de apoio.\n",
            "* **Suporte Psicológico:** Um chatbot de IA que fornece suporte emocional e orientação para sobreviventes que sofrem de estresse pós-traumático.\n",
            "\n",
            "**Benefícios:**\n",
            "\n",
            "* Avaliação rápida e precisa dos danos, permitindo uma resposta mais direcionada.\n",
            "* Coordenação eficiente dos esforços de ajuda, reduzindo a duplicação e melhorando a eficácia.\n",
            "* Rastreamento e assistência aos sobreviventes, garantindo que ninguém seja deixado para trás.\n",
            "* Apoio psicológico oportuno, promovendo a resiliência e o bem-estar dos afetados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "iquO2-7vLqaI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input('Esperando Prompt:')\n",
        "\n",
        "while prompt != 'fim':\n",
        "  response = chat.send_message(prompt)\n",
        "  print('resposta: ', response.text, '\\n')\n",
        "  prompt = input('Esperando Prompt:')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "iPj_vL0fLw6B",
        "outputId": "310583f2-61af-4feb-fdaa-c354554324a2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando Prompt:capital do japao\n",
            "resposta:  Tóquio \n",
            "\n",
            "Esperando Prompt:qual a comida tipica\n",
            "resposta:  Sushi \n",
            "\n",
            "Esperando Prompt:meu primo nasceu, qual nacionalidade\n",
            "resposta:  Japonesa \n",
            "\n",
            "Esperando Prompt:qual populacao ?\n",
            "resposta:  125,5 milhões (2022) \n",
            "\n",
            "Esperando Prompt:de toquio\n",
            "resposta:  9.000.916 (2023) \n",
            "\n",
            "Esperando Prompt:fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viGGGd_bOm1N",
        "outputId": "261cf9c4-f44e-4288-ab6f-0905c6a32fb0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[parts {\n",
              "   text: \"qual a capital do jap\\303\\243o\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"T\\303\\263quio\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"capital do japao\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"T\\303\\263quio\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"qual a comida tipica\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Sushi\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"meu primo nasceu, qual nacionalidade\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Japonesa\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"qual populacao ?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"125,5 milh\\303\\265es (2022)\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"de toquio\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"9.000.916 (2023)\"\n",
              " }\n",
              " role: \"model\"]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melhorando a visualização\n",
        "# Código disponível em https://ai.google.dev/tutorials/python_quickstart#import_packages\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('*','\\*')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "# Imprimindo o histórico\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "print('-------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "b0H0ftAFOpmb",
        "outputId": "1af29472-0d12-43ac-be25-da589eb7d819"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \\*\\*user\\*\\*: qual a capital do japão"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \\*\\*model\\*\\*: Tóquio"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \\*\\*user\\*\\*: capital do japao"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \\*\\*model\\*\\*: Tóquio"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \\*\\*user\\*\\*: qual a comida tipica"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \\*\\*model\\*\\*: Sushi"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \\*\\*user\\*\\*: meu primo nasceu, qual nacionalidade"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \\*\\*model\\*\\*: Japonesa"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \\*\\*user\\*\\*: qual populacao ?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \\*\\*model\\*\\*: 125,5 milhões (2022)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \\*\\*user\\*\\*: de toquio"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \\*\\*model\\*\\*: 9.000.916 (2023)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------\n"
          ]
        }
      ]
    }
  ]
}